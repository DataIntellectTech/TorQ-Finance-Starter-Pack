{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family:Arial; font-size:3.5em;\">Process Checks</span>  \n",
    "   \n",
    "   This notebook will run default process checks on Tickerplant, RDB and HDB.   \n",
    "   Processes are queried via qconnection with the username and password supplied in the credentials.csv file.   \n",
    "   Port numbers are supplied from `. torq.sh summary` table. \n",
    "- - - -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "HTML('''<script>\n",
    "code_show=true; \n",
    "function code_toggle() {\n",
    " if (code_show){\n",
    " $('div.input').hide();\n",
    " } else {\n",
    " $('div.input').show();\n",
    " }\n",
    " code_show = !code_show\n",
    "} \n",
    "$( document ).ready(code_toggle);\n",
    "</script>\n",
    "The raw code for this IPython notebook is by default hidden for easier reading.\n",
    "To toggle on/off the raw code, click <a href=\"javascript:code_toggle()\">here</a>.''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tickerplant Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing required modules\n",
    "from qpython.qconnection import QConnection as qcon\n",
    "from qpython.qcollection import QDictionary as qdict\n",
    "from contextlib import redirect_stdout as rd_so\n",
    "from datetime import datetime\n",
    "from datetime import date\n",
    "import time\n",
    "import psutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "#set qcon variables\n",
    "import csv\n",
    "with open('credentials.csv') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "    line_count = 0\n",
    "    for row in csv_reader:\n",
    "        if line_count == 0:\n",
    "            print(f'Credentials required are {\", \".join(row)}')\n",
    "            line_count += 1\n",
    "        else:\n",
    "            host=row[0]\n",
    "            un=row[1]\n",
    "            pswd=row[2]\n",
    "            print(f'\\t host:{row[0]} username: {row[1]} password: {row[2]}.')\n",
    "            line_count += 1\n",
    "    print(f'Processed {line_count} lines.')         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process Summary\n",
    "\n",
    "Table showing process name, status, PID, Port numbers, CPU and Memory usage.\n",
    "* Process status indicated by colours green (up) and red (down).\n",
    "* Killtick, tpreplay1 and compression1 should usually have a down status indicated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#run torq summary\n",
    "torq_sum= !\"${TORQHOME}\"/torq.sh summary\n",
    "\n",
    "#convert array to numpy array\n",
    "summary=np.asarray(torq_sum)\n",
    "\n",
    "#split each element of array by | character\n",
    "sum_list = [i.split('|') for i in summary]\n",
    "df = pd.DataFrame(sum_list)\n",
    "\n",
    "# take first row and use as header for df\n",
    "new_header = df.iloc[0]\n",
    "df = df[1:]\n",
    "df.columns = new_header\n",
    "\n",
    "#trim whitespace from headers\n",
    "cols=[]\n",
    "for i in df.columns:\n",
    "    cols.append(str.strip(i))\n",
    "df.columns=cols\n",
    "\n",
    "#trim whitespace from all objects within dataframe\n",
    "data = df.select_dtypes(['object'])\n",
    "df[data.columns] = df.apply(lambda x: x.str.strip())\n",
    "\n",
    "#function to extract status of processes - takes a string argument\n",
    "def stat_proc(process):\n",
    "    process_info = df.loc[df['PROCESS'] == process]\n",
    "    STAT = process_info['STATUS'].astype(str)\n",
    "    return STAT\n",
    "\n",
    "# function to extract the port number for each process - takes a string argument\n",
    "def find_portno(process):\n",
    "    process_info = df.loc[df['PROCESS'] == process]\n",
    "    PORT = process_info['PORT'].astype(str).astype(int)\n",
    "    return PORT\n",
    "\n",
    "# function to extract the port number for each process - takes a string argument\n",
    "def find_pid(process):\n",
    "    process_info = df.loc[df['PROCESS'] == process]\n",
    "    PID = process_info['PID'].astype(str).astype(int)\n",
    "    return PID\n",
    "\n",
    "#function to decode bytes to strings\n",
    "def byte_decode(table,cols):\n",
    "    table[cols] = table[cols].applymap(lambda x: x.decode('utf-8'))\n",
    "\n",
    "#function to print mem and cpu stats\n",
    "def print_mem_stats(pid):\n",
    "    with open(\"tmp.txt\",\"a\") as file:\n",
    "        with rd_so(file):\n",
    "            return (psutil.Process(pid)).memory_percent()\n",
    "def print_cpu_stats(pid):\n",
    "    with open(\"tmp.txt\",\"a\") as file:\n",
    "        with rd_so(file):\n",
    "            return (psutil.Process(pid)).cpu_percent(interval =1.0)\n",
    "\n",
    "if stat_proc(\"tickerplant1\").tolist() == [\"down\"]:\n",
    "    print(\"Please check if the following processes are all up: Tickerplant1, rdb1, hdb1\")\n",
    "else:\n",
    "    #return PIDs\n",
    "    df.replace('', np.nan, inplace=True)\n",
    "    pids = df[\"PID\"]\n",
    "    pids = pids.dropna()\n",
    "    pids = [int(i) for i in pids]\n",
    "    \n",
    "    #create array of mem and cpu stats        \n",
    "    mems=[]\n",
    "    cpus=[]\n",
    "    \n",
    "    for pid in pids:\n",
    "        mems.append(print_mem_stats(pid));\n",
    "        cpus.append(print_cpu_stats(pid))\n",
    "        \n",
    "    #insert 0 into cpu/mem for processes that are down     \n",
    "    nopid = df[df['PID'].isnull()].index.tolist()\n",
    "    for i in range(len(nopid)):\n",
    "        mems.insert((nopid[i]-1),0)\n",
    "        cpus.insert((nopid[i]-1),0)\n",
    "    \n",
    "    #append mem and cpu onto summary table    \n",
    "    df['%MEM']=mems\n",
    "    df['%CPU']=cpus\n",
    "    df=df.round({'%MEM':1})\n",
    "    \n",
    "    \n",
    "# set colour on down processes to red and up processes to green\n",
    "def colour_down_red(col):\n",
    "    color = 'red' if 'down' in col else 'green'\n",
    "    return 'color: %s' % color\n",
    "df.style.applymap(colour_down_red, subset=['STATUS'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count of tables in Tickerplant \n",
    "\n",
    "Table to show the count in each table found in the Tickerplant \n",
    "* The counts in each of these tables should be 0, as the Tickerplant should not be storing any data.\n",
    "* If the counts in any of these tables is not 0, this could indicate a slow subscriber."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if stat_proc(\"tickerplant1\").tolist() == [\"up\"]:\n",
    "    with qcon(host, port=find_portno('tickerplant1'), username=un, password=pswd,timeout=3.0) as q:\n",
    "        #counts tickerplant tables\n",
    "        tablecounts = q(\"enlist tables[]!count each value each tables[]\", pandas=True)\n",
    "    display(tablecounts)\n",
    "else:\n",
    "    print('The Tickerplant process is down. Unable to count tables in Tickerplant')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tickerplant Log file size increasing\n",
    "\n",
    "Checks if log messages in the log file of the tickerplant is increasing.\n",
    "   * If log messages are increasing, the tickerplant is receiving data.\n",
    "   * If log messages are not increasing, the tickerplant may not be recieving data. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if stat_proc(\"tickerplant1\").tolist() == [\"up\"]:\n",
    "    with qcon(host, port=find_portno('tickerplant1'), username=un, password=pswd,timeout=3.0) as q:\n",
    "        #counts log file size is increasing \n",
    "        log1=(q(\"hcount .u.L\"))\n",
    "        time.sleep(2)\n",
    "        log2=(q(\"hcount .u.L\"))\n",
    "        print (\"Log file sizes are increasing: \", log1<log2)\n",
    "else:\n",
    "    print('Tickerplant process is down. Unable to check if Tickerplant log files are increasing.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process handles connected to Tickerplant\n",
    "\n",
    "Table to show the handles of processes connected to the tickerplant and if there are any slow subscribers.\n",
    "  *  A process may be a slow subscriber if there is a number value in the output queue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if stat_proc(\"tickerplant1\").tolist() == [\"up\"]:\n",
    "    with qcon(host, port=find_portno('tickerplant1'), username=un, password=pswd,timeout=3.0) as q:\n",
    "    # create pandas dataframe for handles connected to tickerplant\n",
    "        zW=q(\".z.W[]\", pandas=True)\n",
    "        hprocesses=q(\"asc select w,u from .clients.clients\", pandas=True)\n",
    "        byte_decode(hprocesses, ['u'])\n",
    "    # assign columns with new names\n",
    "        keys=pd.DataFrame(zW.keys, columns=['handles'])\n",
    "        values=pd.DataFrame(zW.values, columns=['output queue'])\n",
    "        hprocesses=hprocesses.rename(columns={'u':'processes'})\n",
    "    # apply new names\n",
    "        zW2=keys.join(values)\n",
    "    # join zW2 and hprocesses\n",
    "        zW2=zW2.join(hprocesses.processes)\n",
    "        zW2.set_index('handles', inplace=True)\n",
    "    # Show only table with slow subscribers \n",
    "        display(zW2.loc[zW2['output queue'] > 0])\n",
    "else:\n",
    "    print('The Tickerplant process is down. Unable to check process handles connected to Tickerplant.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RDB Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if stat_proc(\"rdb1\").tolist() == [\"up\"]:\n",
    "    with qcon(host, port=find_portno('rdb1'), username=un, password=pswd,timeout=3.0) as q:\n",
    "        #Check tables in rdb are same as tables in tickerplant \n",
    "        tables = q('all 1_tables[] in ((exec w from .servers.SERVERS where proctype=`tickerplant)0)(\"tables[]\")')\n",
    "        #Check count of tables in rdb - data is being sent from the tickerplant \n",
    "        tptordb = q('enlist tables[]!count each value each tables[]', pandas=True)\n",
    "        time.sleep(3)\n",
    "        tptordb2 = q('enlist tables[]!count each value each tables[]', pandas=True)\n",
    "        #Check that data in table can be queried\n",
    "        rdbtquery=q('5#select from last tables[]', pandas=True)\n",
    "        byte_decode(rdbtquery,['sym'])\n",
    "        tabname=q('last tables[]')\n",
    "        #Check that only data from today is present in the rdb tables\n",
    "        onedatet = q('enlist tables[]!{last exec distinct time.date from x}each tables[]', pandas=True)\n",
    "else:\n",
    "    print('The RDB process is down.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RDB tables\n",
    "\n",
    "Checks if the tables in the rdb are the same as the tables in the Tickerplant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if stat_proc(\"rdb1\").tolist() == [\"up\"]:\n",
    "    print (\"RDB tables are same as Tickerplant tables : \", tables)\n",
    "else:\n",
    "    print('Unable to check if tables in RDB are the same as Tickerplant tables.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RDB table counts\n",
    "\n",
    "Checks to see if data is being sent from the Tickerplant to the RDB\n",
    "* Indicates whether counts in RDB tables are increasing over time (3 second period)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if stat_proc(\"rdb1\").tolist() == [\"up\"]:\n",
    "    tptordb.set_index(tptordb.columns.tolist())\n",
    "    tptordb2.set_index(tptordb2.columns.tolist())\n",
    "    rdb_comp = tptordb < tptordb2\n",
    "    # set colour; True = Green; False = Red\n",
    "    def rdbtable_colour(val):\n",
    "        color = 'IndianRed' if val ==False else 'DarkSeaGreen'\n",
    "        return 'background-color: %s' % color\n",
    "    display(rdb_comp.style.applymap(rdbtable_colour))\n",
    "else:\n",
    "    print('Unable to count RDB tables.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RDB Query\n",
    "Checks to see if tables in the RDB can be queried "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if stat_proc(\"rdb1\").tolist() == [\"up\"]:\n",
    "    print ('Table to be queried:')\n",
    "    name = tabname.decode('UTF-8')\n",
    "    print (name)\n",
    "    display(rdbtquery)\n",
    "else:\n",
    "    print('Unable to query RDB tables.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RDB Date Checks\n",
    "Check to see what what date(s) are in tables \n",
    "* Green indicates that only today's date is in the RDB table\n",
    "* Red indicates there may be more than one date or no date found in the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if stat_proc(\"rdb1\").tolist() == [\"up\"]:\n",
    "    onedatet_col=onedatet.fillna(\"No date\")\n",
    "    def rdbtable_colour(val):\n",
    "        color = 'IndianRed' if val != date.today() else 'DarkSeaGreen'\n",
    "        return 'background-color: %s' % color\n",
    "    display(onedatet_col.style.applymap(rdbtable_colour))\n",
    "else:\n",
    "    print('Unable to check date in RDB tables.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HDB Results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if stat_proc(\"hdb1\").tolist() == [\"up\"]:\n",
    "    with qcon(host, port=find_portno('hdb1'), username=un, password=pswd,timeout=10.0) as q:\n",
    "        #Check hdb table counts excl. eod_summary and eod_summary_iex\n",
    "        hdbtablecount=q('raze{0!select table:x,cnt:count i by date from x where date >=.z.d-5}each tables[] except `heartbeat`logmsg', pandas=True)\n",
    "else:\n",
    "    print('The HDB process is down.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HDB Table Counts\n",
    "* Counts for heartbeat and logmsg should be 0\n",
    "* If counts for other tables are 0, no data has been recieved for the day before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if stat_proc(\"hdb1\").tolist() == [\"up\"]:\n",
    "    if isinstance(hdbtablecount, pd.DataFrame):\n",
    "        byte_decode(hdbtablecount,['table'])\n",
    "        display(hdbtablecount.set_index(hdbtablecount.columns.tolist()))\n",
    "    else:\n",
    "        print('There is no data in the HDB')\n",
    "else:\n",
    "    print('Unable to count HDB tables.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
